<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Examples</title>
<title>Arm Virtual Targets: Examples</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="extra_stylesheet.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="printComponentTabs.js"></script>
<script type="text/javascript" src="footer.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 55px;">
  <td style="padding: 1em;"id="projectlogo"><img alt="Logo" src="arm.png"/></td>
  <td style="padding-left: 2em; padding-bottom: 1em;padding-top: 1em;">
   <div id="projectname">Virtual Hardware Targets
   &#160;<span id="projectnumber">Version 0.1</span>
   </div>
   <div id="projectbrief">Examples Projects and GitHub Repositories</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<div id="Compnav" class="tabs1">
    <ul class="tablist">
      <script type="text/javascript">
		<!--
		writeComponentTabs.call(this);
		//-->
      </script>
	  </ul>
</div>
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Examples </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Folder <code>./examples/</code> contains application projects that demonstrate how to use an Arm VHT System in complex scenarios. The table below gives an overview of existing examples:</p>
<table class="doxtable">
<tr>
<th>Example</th><th>Description </th></tr>
<tr>
<td>Microspeech</td><td>Voice recognition example. Available for FVP and HW targets.<br  />
See <a class="el" href="index.html#examples_microspeech">Microspeech example</a> for details. </td></tr>
<tr>
<td>To be added in next iterations..</td><td></td></tr>
</table>
<h1><a class="anchor" id="examples_microspeech"></a>
Microspeech example</h1>
<p>Micro speech program analyzes an audio input with a voice recognition model that can detect 2 keywords - "yes" and "no". The recognized keywords are then printed into a serial interface. The voice recognition model is implemented using <a href="https://www.tensorflow.org/lite/microcontrollers">TensorFlow Lite for Microcontrollers</a> and is located in <code>./examples/micro_speech/micro_speech/</code> directory.</p>
<p>The example project can be executed on <a class="el" href="index.html#examples_microspeech_fvp">Arm VHT Systems</a> as well as on <a class="el" href="index.html#examples_microspeech_imxrt">a hardware board</a>. This demonstrates how to use the processor and peripheral abstraction layers for simpler software portability across different targets.</p>
<h2><a class="anchor" id="examples_microspeech_pre"></a>
Prerequisites</h2>
<p>Following items are required for running the micro speech example on PC: </p>
<p><b>Toolchain</b></p><ul>
<li>IDE (Windows only): <a href="https://www.keil.com/mdk5">MDK Microcontroller Development Kit</a></li>
<li>alternative command-line tool: <a href="https://github.com/ARM-software/CMSIS_5/releases/download/5.7.0/cbuild_install.0.10.2.sh">CMSIS-Build</a> </li>
</ul>
<p><b>Virtual platform</b></p><ul>
<li>for virtual target with VSI python script interface<ul>
<li><a href="https://www.python.org/downloads/">Python 3.9</a></li>
<li><a href="https://developer.arm.com/tools-and-software/simulation-models/fast-models">Fast Models</a> 11.15</li>
<li>FVP model for Corstone-300 MPS3 with VSI support<ul>
<li>The prebuilt model binaries are available as assets in Git under <a href="https://github.com/RobertRostohar/Orta/releases"><b>Releases</b></a>. The contents of <code>FVP_VSI_Corstone_SSE-300_Ethos-U55_xxx.zip</code> shall be extracted into directory <code>./arm_vsi/Build_Corstone_SSE-300_Ethos-U55/system</code>.</li>
<li>Alternatively, the model executable can be built manually as explained in <code>./arm_vsi/README.md</code>.</li>
</ul>
</li>
</ul>
</li>
<li>for virtual target without VSI support<ul>
<li><a href="https://developer.arm.com/tools-and-software/open-source-software/arm-platforms-software/arm-ecosystem-fvps">Ecosystem FVP for Corstone-300 MPS3</a></li>
</ul>
</li>
</ul>
<p><b>Development boards (for HW target)</b></p><ul>
<li><a href="https://www.nxp.com/design/development-boards/i-mx-evaluation-and-development-boards/mimxrt1064-evk-i-mx-rt1064-evaluation-kit:MIMXRT1064-EVK">NXP MIMXRT1064-EVK</a></li>
</ul>
<p><a href="https://developer.arm.com/tools-and-software/embedded/cmsis/cmsis-packs"><b>Public CMSIS Software Packs</b></a></p><ul>
<li>ARM::CMSIS 5.8.0</li>
<li>Keil::ARM_Compiler 1.6.3</li>
<li>specifically for virtual targets:<ul>
<li>ARM::V2M_MPS3_SSE_300_BSP 1.2.0</li>
</ul>
</li>
<li>specifically for HW MIMXRT1064-EVK target:<ul>
<li>ARM::CMSIS-Driver 2.6.1</li>
<li>NXP::MIMXRT1064_DFP 13.0.0</li>
<li>NXP::EVK-MIMXRT1064_BSP 13.0.0</li>
<li>Keil::MIMXRT1064-EVK_BSP 1.2.1</li>
<li>Keil::iMXRT1064_MWP 1.4.0</li>
</ul>
</li>
</ul>
<p><b>Non-public CMSIS Software Packs</b></p><ul>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/tensorflow.flatbuffers.0.1.20210719.pack">tensorflow.flatbuffers.0.1.20210719</a></li>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/tensorflow.gemmlowp.0.0.1.20210719.pack">tensorflow.gemmlowp.0.0.1.20210719</a></li>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/tensorflow.kissfft.0.1.20210719.pack">kissfft.0.1.20210719</a></li>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/tensorflow.ruy.0.1.20210719.pack">tensorflow.ruy.0.1.20210719</a></li>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/tensorflow.tensorflow-lite-micro.0.2.20210719.pack">tensorflow.tensorflow-lite-micro.0.2.20210719</a></li>
<li><a href="https://github.com/MDK-Packs/tensorflow-pack/releases/download/preview-0.3/Arm.ethos-u-core-driver.0.1.20210719.pack">Arm.ethos-u-core-driver.0.1.20210719</a> (for virtual target with Ethos-U55)</li>
</ul>
<h2><a class="anchor" id="examples_microspeech_fvp"></a>
Running on a virtual target</h2>
<p>Directory <code>./examples/micro_speech/Platform_FVP_Corstone_SSE-300_Ethos-U55/</code> contains the project files for executing the Micro speech example on virtual targets.</p>
<p>The program can be executed on two types of virtual targets:</p><ul>
<li><b>with VSI support</b>: implements audio driver on VSI peripheral with audio test data provided through Python script as explained in <a href="../../simulation/html/index.html"><b>Simulation</b></a> chapter.</li>
<li><b>without VSI support</b>: integrates audio test data into embedded code and can be run on ecosystem FVPs without VSI support.</li>
</ul>
<p>Below is the description of available project targets with execution instructions:</p>
<p><b>Example</b> target: runs on a virtual target <b>with VSI support</b></p><ul>
<li>Uses customized Corstone SSE-300 Ethos-U55 FVP with Virtual Streaming Interface (VSI). Refer to virtual platform setup described in <a class="el" href="index.html#examples_microspeech_pre">Prerequisites</a>.</li>
<li>Audio test data is provided by Python script <code>./audio/audio_in/python/arm_vsi0.py</code> from WAVE file <code>test.wav</code> which contains keywords 'Yes' and 'No' alternating three times.</li>
<li>Build example with MDK using uVision project <code>microspeech.uvprojx</code> and target <code>Example</code> or CMSIS-Build using <code>microspeech.Example.cprj</code> project.</li>
<li>Run example with MDK or standalone with script <code>run_example.cmd</code>.</li>
<li>When running the example the audio data is processed and detected keywords are output to the Telnet terminal. For example as follows: <br  />
<code> Heard yes (152) @1100ms <br  />
 Heard no (141) @5500ms <br  />
 Heard yes (147) @9100ms <br  />
 Heard no (148) @13600ms <br  />
 Heard yes (147) @17100ms <br  />
 Heard no (148) @21600ms <br  />
 </code></li>
</ul>
<p><b>Example Test</b>: internal test for the Example target<br  />
</p>
<p><b>Audio Provider Mock</b>: runs on a virtual target <b>without VSI support</b></p><ul>
<li>Uses <a href="https://developer.arm.com/tools-and-software/open-source-software/arm-platforms-software/arm-ecosystem-fvps"><b>ecosystem FVP for Corstone-300 MPS3</b></a>.<ul>
<li>By default following path is used for the FVP: <code>c:\Program Files\ARM\FVP_Corstone_SSE-300_Ethos-U55\models\Win64_VC2017\FVP_Corstone_SSE-300_Ethos-U55.exe</code>. Update it in the uVision project or in the execution script if necessary.</li>
</ul>
</li>
<li>Audio test data is embedded in the test code and contains keywords 'Yes' and 'No' alternating indefinitely.</li>
<li>Build example with MDK using uVision project <code>microspeech.uvprojx</code> target <code>Audio Provider Mock</code> or CMSIS-Build using <code>microspeech.Audio_Provider_Mock.cprj</code> project.</li>
<li>Run example with MDK or standalone with script <code>run_audio_provider_mock.cmd</code>.</li>
<li>When running the example the audio data is processed and detected keywords are continuously output to the Telnet terminal. For example as follows: <br  />
<code> Heard silence (149) @400ms <br  />
 Heard yes (158) @1200ms <br  />
 Heard no (143) @5600ms <br  />
 Heard yes (149) @9100ms <br  />
 Heard no (142) @13600ms <br  />
 Heard yes (149) @17100ms <br  />
 Heard no (142) @21600ms <br  />
 ... </code></li>
</ul>
<p><b>Audio Provider Mock Test</b>: internal test for Audio Provider Mock target</p>
<h2><a class="anchor" id="examples_microspeech_imxrt"></a>
Running on a hardware target</h2>
<p>Directory <code>./examples/micro_speech/Platform_MIMXRT1064-EVK/</code> contains the project files for executing the Micro speech example on <a href="https://www.nxp.com/design/development-boards/i-mx-evaluation-and-development-boards/mimxrt1064-evk-i-mx-rt1064-evaluation-kit:MIMXRT1064-EVK">NXP MIMXRT1064-EVK</a> development board with an Arm Cortex-M7 processor. One target <b>MIMXRT1064-EVK</b> is provided in the project.</p>
<p>This projects uses the on-board microphone for audio input and prints recognized keywords to the serial interface.</p>
<p>The hardware setup is simple and requires only connection to the PC via USB. The project is configured to load the program to QSPI NOR flash so the boot switch SW7 shall be set to 0010.</p>
<div class="image">
<img src="mimxrt1064_hw_setup.png" alt=""/>
<div class="caption">
MIMXRT1064-EVK board setup</div></div>
<p>Execute the program in following steps:</p><ul>
<li>Build example with MDK using uVision project <code>microspeech.uvprojx</code> or CMSIS-Build using <code>microspeech.MIMXRT1064-EVK.cprj</code> project.</li>
<li>Program and run the example with MDK or use Drag-and-drop programming through the DAP-Link drive.</li>
<li>Open the DAP-Link Virtual COM port in a terminal (baudrate = 115200), speak the keywords and monitor recognition results in the terminal window. </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
	Copyright &copy; 2021 Arm Limited (or its affiliates). All rights reserved.
	<!-- Use script below for auto-inserting date, project name, version, etc  -->
	<!-- <script type="text/javascript">
        writeFooter.call(this);
    </script> -->
    </li>
  </ul>
</div>
</body>
</html>
